# Phase 0 TODO: ì¤€ë¹„ ë‹¨ê³„ (2ì£¼)

> **ëª©í‘œ**: ë¬´ì¤‘ë‹¨ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ìœ„í•œ ì„€ë„ ìŠ¤í‚¤ë§ˆ ë° ìë™í™” êµ¬ì¶•
> **ê¸°ê°„**: 2ì£¼ (10 ì˜ì—…ì¼)
> **ë¦¬ìŠ¤í¬**: ë‚®ìŒ (í”„ë¡œë•ì…˜ ì˜í–¥ ì—†ìŒ, ì½ê¸° ì „ìš© ê²€ì¦)

---

## ğŸ“Š ì „ì²´ íƒ€ì„ë¼ì¸

```
Week 1 (Day 1-5)  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ì„€ë„ ìŠ¤í‚¤ë§ˆ + ë°±í•„
Week 2 (Day 6-10) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ê²€ì¦ ìë™í™” + ì´ì¤‘ì“°ê¸° ì¤€ë¹„
```

---

## Week 1: ì„€ë„ ìŠ¤í‚¤ë§ˆ + ë°±í•„

### Day 1-2: ì„€ë„ ìŠ¤í‚¤ë§ˆ ìƒì„± (Shadow Schema Creation)

**ëª©í‘œ**: ìƒˆ í…Œì´ë¸”ì„ í”„ë¡œë•ì…˜ì— ì˜í–¥ ì—†ì´ ìƒì„±

#### âœ… Task 1.1: ìƒˆ í…Œì´ë¸” ìƒì„± (ì œì•½ ì¡°ê±´ `NOT VALID`)
**íŒŒì¼**: `supabase/migrations/001_create_shadow_schema.sql`

```sql
-- 1. children í…Œì´ë¸”
CREATE TABLE children (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  user_id UUID NOT NULL,
  name TEXT NOT NULL,
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  CONSTRAINT fk_children_user FOREIGN KEY (user_id)
    REFERENCES auth.users(id) NOT VALID  -- ì œì•½ ì¡°ê±´ì„ ê²€ì¦í•˜ì§€ ì•ŠìŒ (ë¹ ë¥¸ ìƒì„±)
);

-- 2. weeks í…Œì´ë¸”
CREATE TABLE weeks (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  child_id UUID NOT NULL,
  week_start_date DATE NOT NULL,
  week_end_date DATE NOT NULL,
  theme TEXT,
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  source_version TEXT DEFAULT 'new_schema',  -- 'dual_write', 'new_schema', 'migration'
  CONSTRAINT fk_weeks_child FOREIGN KEY (child_id)
    REFERENCES children(id) ON DELETE CASCADE NOT VALID
);

-- 3. habits í…Œì´ë¸”
CREATE TABLE habits (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  week_id UUID NOT NULL,
  text TEXT NOT NULL,
  sort_order INTEGER NOT NULL DEFAULT 0,
  color TEXT DEFAULT '#3B82F6',
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  CONSTRAINT fk_habits_week FOREIGN KEY (week_id)
    REFERENCES weeks(id) ON DELETE CASCADE NOT VALID
);

-- 4. completions í…Œì´ë¸”
CREATE TABLE completions (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  habit_id UUID NOT NULL,
  completed_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  day_of_week INTEGER NOT NULL CHECK (day_of_week BETWEEN 0 AND 6),
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  CONSTRAINT fk_completions_habit FOREIGN KEY (habit_id)
    REFERENCES habits(id) ON DELETE CASCADE NOT VALID,
  CONSTRAINT unique_habit_day UNIQUE (habit_id, day_of_week) NOT VALID
);

-- 5. templates í…Œì´ë¸”
CREATE TABLE templates (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  user_id UUID NOT NULL,
  name TEXT NOT NULL,
  description TEXT,
  is_public BOOLEAN DEFAULT false,
  theme TEXT,
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  CONSTRAINT fk_templates_user FOREIGN KEY (user_id)
    REFERENCES auth.users(id) NOT VALID
);

-- 6. template_habits í…Œì´ë¸”
CREATE TABLE template_habits (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  template_id UUID NOT NULL,
  text TEXT NOT NULL,
  sort_order INTEGER NOT NULL DEFAULT 0,
  color TEXT DEFAULT '#3B82F6',
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  CONSTRAINT fk_template_habits_template FOREIGN KEY (template_id)
    REFERENCES templates(id) ON DELETE CASCADE NOT VALID
);

-- 7. statistics í…Œì´ë¸”
CREATE TABLE statistics (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  child_id UUID NOT NULL,
  week_start_date DATE NOT NULL,
  total_habits INTEGER NOT NULL DEFAULT 0,
  total_completions INTEGER NOT NULL DEFAULT 0,
  completion_rate DECIMAL(5, 2) NOT NULL DEFAULT 0.00,
  streak_days INTEGER NOT NULL DEFAULT 0,
  calculated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  CONSTRAINT fk_statistics_child FOREIGN KEY (child_id)
    REFERENCES children(id) ON DELETE CASCADE NOT VALID,
  CONSTRAINT unique_child_week UNIQUE (child_id, week_start_date) NOT VALID
);
```

**ê²€ì¦**:
```bash
# Supabase CLIë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
npx supabase db push

# í…Œì´ë¸” ìƒì„± í™•ì¸
npx supabase db query "SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name IN ('children', 'weeks', 'habits', 'completions', 'templates', 'template_habits', 'statistics');"
```

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] 7ê°œ í…Œì´ë¸” ëª¨ë‘ ìƒì„±ë¨
- [ ] `NOT VALID` ì œì•½ ì¡°ê±´ìœ¼ë¡œ ë¹ ë¥´ê²Œ ìƒì„±ë¨ (í”„ë¡œë•ì…˜ ì˜í–¥ ì—†ìŒ)
- [ ] ë§ˆì´ê·¸ë ˆì´ì…˜ íŒŒì¼ì´ Gitì— ì»¤ë°‹ë¨

---

#### âœ… Task 1.2: ì¸ë±ìŠ¤ ìƒì„± (CONCURRENTLY)
**íŒŒì¼**: `supabase/migrations/002_create_indexes.sql`

```sql
-- ì¸ë±ìŠ¤ëŠ” CONCURRENTLYë¡œ ìƒì„± (ì ê¸ˆ ë°©ì§€)
CREATE INDEX CONCURRENTLY idx_children_user_id ON children(user_id);
CREATE INDEX CONCURRENTLY idx_children_name ON children(name);

CREATE INDEX CONCURRENTLY idx_weeks_child_id ON weeks(child_id);
CREATE INDEX CONCURRENTLY idx_weeks_start_date ON weeks(week_start_date);
CREATE INDEX CONCURRENTLY idx_weeks_source_version ON weeks(source_version);

CREATE INDEX CONCURRENTLY idx_habits_week_id ON habits(week_id);
CREATE INDEX CONCURRENTLY idx_habits_sort_order ON habits(week_id, sort_order);

CREATE INDEX CONCURRENTLY idx_completions_habit_id ON completions(habit_id);
CREATE INDEX CONCURRENTLY idx_completions_day ON completions(habit_id, day_of_week);

CREATE INDEX CONCURRENTLY idx_templates_user_id ON templates(user_id);
CREATE INDEX CONCURRENTLY idx_templates_public ON templates(is_public) WHERE is_public = true;

CREATE INDEX CONCURRENTLY idx_template_habits_template_id ON template_habits(template_id);

CREATE INDEX CONCURRENTLY idx_statistics_child_week ON statistics(child_id, week_start_date);
```

**ê²€ì¦**:
```bash
npx supabase db query "SELECT tablename, indexname, indexdef FROM pg_indexes WHERE schemaname = 'public' AND tablename IN ('children', 'weeks', 'habits', 'completions', 'templates', 'template_habits', 'statistics');"
```

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] ëª¨ë“  ì¸ë±ìŠ¤ê°€ CONCURRENTLYë¡œ ìƒì„±ë¨
- [ ] ì¸ë±ìŠ¤ ìƒì„± ì¤‘ í”„ë¡œë•ì…˜ ì ê¸ˆ ì—†ìŒ í™•ì¸

---

#### âœ… Task 1.3: RLS ì •ì±… ìƒì„± (ë¹„í™œì„±í™” ìƒíƒœ)
**íŒŒì¼**: `supabase/migrations/003_create_rls_policies.sql`

```sql
-- RLS ì •ì±… ìƒì„± (ì•„ì§ í™œì„±í™”í•˜ì§€ ì•ŠìŒ)

-- children í…Œì´ë¸”
CREATE POLICY policy_children_select ON children
  FOR SELECT USING (auth.uid() = user_id);

CREATE POLICY policy_children_insert ON children
  FOR INSERT WITH CHECK (auth.uid() = user_id);

CREATE POLICY policy_children_update ON children
  FOR UPDATE USING (auth.uid() = user_id);

CREATE POLICY policy_children_delete ON children
  FOR DELETE USING (auth.uid() = user_id);

-- weeks í…Œì´ë¸”
CREATE POLICY policy_weeks_select ON weeks
  FOR SELECT USING (
    EXISTS (
      SELECT 1 FROM children
      WHERE children.id = weeks.child_id
      AND children.user_id = auth.uid()
    )
  );

CREATE POLICY policy_weeks_insert ON weeks
  FOR INSERT WITH CHECK (
    EXISTS (
      SELECT 1 FROM children
      WHERE children.id = weeks.child_id
      AND children.user_id = auth.uid()
    )
  );

CREATE POLICY policy_weeks_update ON weeks
  FOR UPDATE USING (
    EXISTS (
      SELECT 1 FROM children
      WHERE children.id = weeks.child_id
      AND children.user_id = auth.uid()
    )
  );

CREATE POLICY policy_weeks_delete ON weeks
  FOR DELETE USING (
    EXISTS (
      SELECT 1 FROM children
      WHERE children.id = weeks.child_id
      AND children.user_id = auth.uid()
    )
  );

-- habits, completions, templates, template_habits, statisticsë„ ë™ì¼í•œ íŒ¨í„´ìœ¼ë¡œ ì‘ì„±
-- (ìƒëµ - ì „ì²´ ì½”ë“œëŠ” DB_MIGRATION_PLAN_V2.md ì°¸ì¡°)

-- âš ï¸ ì¤‘ìš”: RLSëŠ” ì•„ì§ í™œì„±í™”í•˜ì§€ ì•ŠìŒ!
-- ALTER TABLE children ENABLE ROW LEVEL SECURITY;  -- Phase 2ì—ì„œ í™œì„±í™”
```

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] RLS ì •ì±…ì´ ìƒì„±ë¨ (ë¹„í™œì„±í™” ìƒíƒœ)
- [ ] Phase 2ê¹Œì§€ RLSëŠ” êº¼ì ¸ ìˆìŒì„ í™•ì¸

---

### Day 3-4: ë°±í•„ ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ê°œë°œ

**ëª©í‘œ**: ê¸°ì¡´ ë°ì´í„°ë¥¼ ìƒˆ ìŠ¤í‚¤ë§ˆë¡œ ì´ê´€í•˜ëŠ” ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

#### âœ… Task 2.1: ë°±í•„ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
**íŒŒì¼**: `scripts/backfill.js`

```javascript
import { createClient } from '@supabase/supabase-js';

const supabase = createClient(
  process.env.VITE_SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY  // ì„œë¹„ìŠ¤ ì—­í•  í‚¤ í•„ìš”
);

const BATCH_SIZE = 1000;
const DRY_RUN = process.argv.includes('--dry-run');

// 1. children ë°±í•„
async function backfillChildren() {
  console.log('\nğŸ“¦ ë°±í•„ ì‹œì‘: children í…Œì´ë¸”');

  const { data: oldData, error } = await supabase
    .from('habit_tracker')
    .select('child_name, user_id, created_at')
    .order('id');

  if (error) throw error;

  // ì¤‘ë³µ ì œê±°
  const uniqueChildren = new Map();
  for (const row of oldData) {
    if (!uniqueChildren.has(row.child_name)) {
      uniqueChildren.set(row.child_name, {
        user_id: row.user_id || '00000000-0000-0000-0000-000000000000',
        name: row.child_name,
        created_at: row.created_at || new Date().toISOString()
      });
    }
  }

  const childrenArray = Array.from(uniqueChildren.values());
  console.log(`âœ… ì´ ${childrenArray.length}ëª…ì˜ ì•„ì´ ë°œê²¬`);

  if (DRY_RUN) {
    console.log('ğŸ” DRY RUN: ì‹¤ì œ ì‚½ì…í•˜ì§€ ì•ŠìŒ');
    console.log(childrenArray.slice(0, 5));  // ìƒ˜í”Œ ì¶œë ¥
    return;
  }

  // ë°°ì¹˜ ì‚½ì…
  for (let i = 0; i < childrenArray.length; i += BATCH_SIZE) {
    const batch = childrenArray.slice(i, i + BATCH_SIZE);
    const { error: insertError } = await supabase
      .from('children')
      .upsert(batch, {
        onConflict: 'name',
        ignoreDuplicates: false
      });

    if (insertError) throw insertError;
    console.log(`   ì§„í–‰: ${Math.min(i + BATCH_SIZE, childrenArray.length)}/${childrenArray.length}`);
  }

  console.log('âœ… children ë°±í•„ ì™„ë£Œ');
}

// 2. weeks ë°±í•„
async function backfillWeeks() {
  console.log('\nğŸ“¦ ë°±í•„ ì‹œì‘: weeks í…Œì´ë¸”');

  const { data: oldData, error } = await supabase
    .from('habit_tracker')
    .select('*')
    .order('id');

  if (error) throw error;

  // children ID ë§¤í•‘
  const { data: childrenData } = await supabase
    .from('children')
    .select('id, name');

  const childNameToId = new Map(
    childrenData.map(c => [c.name, c.id])
  );

  const weeksData = oldData.map(row => ({
    child_id: childNameToId.get(row.child_name),
    week_start_date: row.week_start_date,
    week_end_date: calculateWeekEnd(row.week_start_date),
    theme: row.theme,
    created_at: row.created_at || new Date().toISOString(),
    source_version: 'migration'
  })).filter(w => w.child_id);  // child_id ì—†ëŠ” í–‰ ì œê±°

  console.log(`âœ… ì´ ${weeksData.length}ê°œì˜ ì£¼ì°¨ ë°œê²¬`);

  if (DRY_RUN) {
    console.log('ğŸ” DRY RUN: ì‹¤ì œ ì‚½ì…í•˜ì§€ ì•ŠìŒ');
    console.log(weeksData.slice(0, 5));
    return;
  }

  // ë°°ì¹˜ ì‚½ì…
  for (let i = 0; i < weeksData.length; i += BATCH_SIZE) {
    const batch = weeksData.slice(i, i + BATCH_SIZE);
    const { error: insertError } = await supabase
      .from('weeks')
      .upsert(batch, {
        onConflict: 'child_id,week_start_date',
        ignoreDuplicates: false
      });

    if (insertError) throw insertError;
    console.log(`   ì§„í–‰: ${Math.min(i + BATCH_SIZE, weeksData.length)}/${weeksData.length}`);
  }

  console.log('âœ… weeks ë°±í•„ ì™„ë£Œ');
}

// 3. habits ë°±í•„
async function backfillHabits() {
  console.log('\nğŸ“¦ ë°±í•„ ì‹œì‘: habits í…Œì´ë¸”');

  const { data: oldData, error } = await supabase
    .from('habit_tracker')
    .select('*')
    .order('id');

  if (error) throw error;

  // weeks ID ë§¤í•‘
  const { data: weeksData } = await supabase
    .from('weeks')
    .select('id, child_id, week_start_date')
    .order('week_start_date');

  const { data: childrenData } = await supabase
    .from('children')
    .select('id, name');

  const childNameToId = new Map(
    childrenData.map(c => [c.name, c.id])
  );

  const weekKey = (childId, weekStart) => `${childId}_${weekStart}`;
  const weekMap = new Map(
    weeksData.map(w => [weekKey(w.child_id, w.week_start_date), w.id])
  );

  const habitsData = [];
  for (const row of oldData) {
    const childId = childNameToId.get(row.child_name);
    const weekId = weekMap.get(weekKey(childId, row.week_start_date));

    if (!weekId) continue;

    const habits = JSON.parse(row.habits || '[]');
    for (let i = 0; i < habits.length; i++) {
      habitsData.push({
        week_id: weekId,
        text: habits[i].text || habits[i],
        sort_order: i,
        color: habits[i].color || '#3B82F6',
        created_at: row.created_at || new Date().toISOString()
      });
    }
  }

  console.log(`âœ… ì´ ${habitsData.length}ê°œì˜ ìŠµê´€ ë°œê²¬`);

  if (DRY_RUN) {
    console.log('ğŸ” DRY RUN: ì‹¤ì œ ì‚½ì…í•˜ì§€ ì•ŠìŒ');
    console.log(habitsData.slice(0, 5));
    return;
  }

  // ë°°ì¹˜ ì‚½ì…
  for (let i = 0; i < habitsData.length; i += BATCH_SIZE) {
    const batch = habitsData.slice(i, i + BATCH_SIZE);
    const { error: insertError } = await supabase
      .from('habits')
      .insert(batch);

    if (insertError) throw insertError;
    console.log(`   ì§„í–‰: ${Math.min(i + BATCH_SIZE, habitsData.length)}/${habitsData.length}`);
  }

  console.log('âœ… habits ë°±í•„ ì™„ë£Œ');
}

// 4. completions ë°±í•„
async function backfillCompletions() {
  console.log('\nğŸ“¦ ë°±í•„ ì‹œì‘: completions í…Œì´ë¸”');

  const { data: oldData, error } = await supabase
    .from('habit_tracker')
    .select('*')
    .order('id');

  if (error) throw error;

  // habits ID ë§¤í•‘ (ë³µì¡í•˜ë¯€ë¡œ JOIN ì‚¬ìš©)
  const completionsData = [];

  for (const row of oldData) {
    const habits = JSON.parse(row.habits || '[]');

    for (let habitIdx = 0; habitIdx < habits.length; habitIdx++) {
      const habit = habits[habitIdx];
      const checks = habit.checks || [];

      for (let dayIdx = 0; dayIdx < checks.length; dayIdx++) {
        if (checks[dayIdx]) {
          // habit IDë¥¼ ì°¾ê¸° ìœ„í•´ ì¿¼ë¦¬ í•„ìš”
          const { data: habitData } = await supabase
            .from('habits')
            .select('id')
            .eq('week_id', row.week_id)  // ì´ì „ ë‹¨ê³„ì—ì„œ ë§¤í•‘ í•„ìš”
            .eq('sort_order', habitIdx)
            .single();

          if (habitData) {
            completionsData.push({
              habit_id: habitData.id,
              day_of_week: dayIdx,
              completed_at: calculateCompletionDate(row.week_start_date, dayIdx),
              created_at: row.created_at || new Date().toISOString()
            });
          }
        }
      }
    }
  }

  console.log(`âœ… ì´ ${completionsData.length}ê°œì˜ ì™„ë£Œ ê¸°ë¡ ë°œê²¬`);

  if (DRY_RUN) {
    console.log('ğŸ” DRY RUN: ì‹¤ì œ ì‚½ì…í•˜ì§€ ì•ŠìŒ');
    console.log(completionsData.slice(0, 5));
    return;
  }

  // ë°°ì¹˜ ì‚½ì…
  for (let i = 0; i < completionsData.length; i += BATCH_SIZE) {
    const batch = completionsData.slice(i, i + BATCH_SIZE);
    const { error: insertError } = await supabase
      .from('completions')
      .insert(batch);

    if (insertError) throw insertError;
    console.log(`   ì§„í–‰: ${Math.min(i + BATCH_SIZE, completionsData.length)}/${completionsData.length}`);
  }

  console.log('âœ… completions ë°±í•„ ì™„ë£Œ');
}

// í—¬í¼ í•¨ìˆ˜ë“¤
function calculateWeekEnd(weekStart) {
  const date = new Date(weekStart);
  date.setDate(date.getDate() + 6);
  return date.toISOString().split('T')[0];
}

function calculateCompletionDate(weekStart, dayOfWeek) {
  const date = new Date(weekStart);
  date.setDate(date.getDate() + dayOfWeek);
  return date.toISOString();
}

// ë©”ì¸ ì‹¤í–‰
async function main() {
  console.log('ğŸš€ ë°±í•„ í”„ë¡œì„¸ìŠ¤ ì‹œì‘');
  console.log(`âš™ï¸  ëª¨ë“œ: ${DRY_RUN ? 'DRY RUN' : 'PRODUCTION'}`);

  try {
    await backfillChildren();
    await backfillWeeks();
    await backfillHabits();
    await backfillCompletions();

    console.log('\nâœ… ëª¨ë“  ë°±í•„ ì™„ë£Œ!');
  } catch (error) {
    console.error('âŒ ë°±í•„ ì˜¤ë¥˜:', error);
    process.exit(1);
  }
}

main();
```

**ì‹¤í–‰**:
```bash
# Dry runìœ¼ë¡œ ë¨¼ì € í…ŒìŠ¤íŠ¸
node scripts/backfill.js --dry-run

# ì‹¤ì œ ì‹¤í–‰
node scripts/backfill.js
```

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] ë°±í•„ ìŠ¤í¬ë¦½íŠ¸ê°€ ì‘ì„±ë¨
- [ ] Dry runìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ
- [ ] ì‹¤ì œ ë°±í•„ ì‹¤í–‰ ì™„ë£Œ (ë°ì´í„° ì´ê´€ í™•ì¸)

---

#### âœ… Task 2.2: ë°±í•„ ê²€ì¦ ì¿¼ë¦¬
**íŒŒì¼**: `scripts/validate-backfill.sql`

```sql
-- 1. children ê°œìˆ˜ ë¹„êµ
SELECT
  'êµ¬ ìŠ¤í‚¤ë§ˆ' AS source,
  COUNT(DISTINCT child_name) AS count
FROM habit_tracker
UNION ALL
SELECT
  'ì‹  ìŠ¤í‚¤ë§ˆ' AS source,
  COUNT(*) AS count
FROM children;

-- 2. weeks ê°œìˆ˜ ë¹„êµ
SELECT
  'êµ¬ ìŠ¤í‚¤ë§ˆ' AS source,
  COUNT(*) AS count
FROM habit_tracker
UNION ALL
SELECT
  'ì‹  ìŠ¤í‚¤ë§ˆ' AS source,
  COUNT(*) AS count
FROM weeks;

-- 3. habits ê°œìˆ˜ ë¹„êµ
SELECT
  'êµ¬ ìŠ¤í‚¤ë§ˆ' AS source,
  SUM(jsonb_array_length(habits)) AS count
FROM habit_tracker
UNION ALL
SELECT
  'ì‹  ìŠ¤í‚¤ë§ˆ' AS source,
  COUNT(*) AS count
FROM habits;

-- 4. completions ê°œìˆ˜ ë¹„êµ
WITH old_completions AS (
  SELECT
    jsonb_array_elements(habits) AS habit,
    jsonb_array_length(jsonb_array_elements(habits)->'checks') AS check_count
  FROM habit_tracker
)
SELECT
  'êµ¬ ìŠ¤í‚¤ë§ˆ' AS source,
  SUM(check_count) AS count
FROM old_completions
UNION ALL
SELECT
  'ì‹  ìŠ¤í‚¤ë§ˆ' AS source,
  COUNT(*) AS count
FROM completions;

-- 5. ìƒ˜í”Œ ë°ì´í„° ë¹„êµ
SELECT
  ht.child_name,
  ht.week_period,
  c.name,
  w.week_start_date,
  COUNT(h.id) AS habit_count
FROM habit_tracker ht
LEFT JOIN children c ON c.name = ht.child_name
LEFT JOIN weeks w ON w.child_id = c.id AND w.week_start_date = ht.week_start_date
LEFT JOIN habits h ON h.week_id = w.id
GROUP BY ht.child_name, ht.week_period, c.name, w.week_start_date
LIMIT 10;
```

**ì‹¤í–‰**:
```bash
npx supabase db query --file scripts/validate-backfill.sql
```

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] êµ¬/ì‹  ìŠ¤í‚¤ë§ˆ ë°ì´í„° ê°œìˆ˜ê°€ ì¼ì¹˜í•¨
- [ ] ìƒ˜í”Œ ë°ì´í„° ë¹„êµ ì‹œ ë‚´ìš© ì¼ì¹˜ í™•ì¸

---

### Day 5: Week 1 ê²€ì¦ ë° ë¬¸ì„œí™”

#### âœ… Task 3.1: Week 1 ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
**ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] 7ê°œ í…Œì´ë¸” ëª¨ë‘ ìƒì„±ë¨
- [ ] ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ (ì ê¸ˆ ì—†ìŒ)
- [ ] RLS ì •ì±… ìƒì„±ë¨ (ë¹„í™œì„±í™” ìƒíƒœ)
- [ ] ë°±í•„ ì™„ë£Œ (ë°ì´í„° ê°œìˆ˜ ì¼ì¹˜)
- [ ] ì™¸ë˜ í‚¤ ì œì•½ ì¡°ê±´ ì¡´ì¬ (`NOT VALID` ìƒíƒœ)

#### âœ… Task 3.2: Week 1 íšŒê³  ë¬¸ì„œ ì‘ì„±
**íŒŒì¼**: `docs/phase0-week1-retrospective.md`

```markdown
# Phase 0 Week 1 íšŒê³ 

## ì™„ë£Œëœ ì‘ì—…
- âœ… ì„€ë„ ìŠ¤í‚¤ë§ˆ ìƒì„± (7ê°œ í…Œì´ë¸”)
- âœ… ì¸ë±ìŠ¤ ìƒì„± (CONCURRENTLY)
- âœ… RLS ì •ì±… ìƒì„± (ë¹„í™œì„±í™”)
- âœ… ë°±í•„ ìë™í™” ìŠ¤í¬ë¦½íŠ¸
- âœ… ë°ì´í„° ì´ê´€ ì™„ë£Œ

## ë°ì´í„° í†µê³„
- ì´ ì•„ì´: XXëª…
- ì´ ì£¼ì°¨: XXê°œ
- ì´ ìŠµê´€: XXê°œ
- ì´ ì™„ë£Œ ê¸°ë¡: XXê°œ

## ì´ìŠˆ ë° í•´ê²°
- (ì´ìŠˆê°€ ìˆì—ˆë‹¤ë©´ ê¸°ë¡)

## ë‹¤ìŒ ì£¼ ê³„íš
- ë“œë¦¬í”„íŠ¸ ê²€ì¦ ìë™í™”
- ì´ì¤‘ì“°ê¸° ì¤€ë¹„
```

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] Week 1 íšŒê³  ë¬¸ì„œ ì‘ì„± ì™„ë£Œ
- [ ] Gitì— ì»¤ë°‹ ë° í‘¸ì‹œ

---

## Week 2: ê²€ì¦ ìë™í™” + ì´ì¤‘ì“°ê¸° ì¤€ë¹„

### Day 6-7: ë“œë¦¬í”„íŠ¸ ê²€ì¦ ìë™í™”

**ëª©í‘œ**: êµ¬/ì‹  ìŠ¤í‚¤ë§ˆ ê°„ ë°ì´í„° ë¶ˆì¼ì¹˜ë¥¼ ìë™ìœ¼ë¡œ ê°ì§€

#### âœ… Task 4.1: ë“œë¦¬í”„íŠ¸ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
**íŒŒì¼**: `scripts/drift-detection.js`

```javascript
import { createClient } from '@supabase/supabase-js';

const supabase = createClient(
  process.env.VITE_SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY
);

async function detectDrift() {
  console.log('ğŸ” ë“œë¦¬í”„íŠ¸ ê²€ì¦ ì‹œì‘...');
  const issues = [];

  // 1. children ê°œìˆ˜ ë¹„êµ
  const { data: oldChildren } = await supabase
    .from('habit_tracker')
    .select('child_name', { count: 'exact', head: true });

  const { data: newChildren } = await supabase
    .from('children')
    .select('*', { count: 'exact', head: true });

  if (oldChildren.count !== newChildren.count) {
    issues.push({
      table: 'children',
      type: 'count_mismatch',
      old: oldChildren.count,
      new: newChildren.count
    });
  }

  // 2. weeks ê°œìˆ˜ ë¹„êµ
  const { data: oldWeeks } = await supabase
    .from('habit_tracker')
    .select('*', { count: 'exact', head: true });

  const { data: newWeeks } = await supabase
    .from('weeks')
    .select('*', { count: 'exact', head: true });

  if (oldWeeks.count !== newWeeks.count) {
    issues.push({
      table: 'weeks',
      type: 'count_mismatch',
      old: oldWeeks.count,
      new: newWeeks.count
    });
  }

  // 3. ìƒ˜í”Œ ë°ì´í„° ë‚´ìš© ë¹„êµ
  const { data: sampleOld } = await supabase
    .from('habit_tracker')
    .select('*')
    .limit(10);

  for (const oldRow of sampleOld) {
    const { data: child } = await supabase
      .from('children')
      .select('id')
      .eq('name', oldRow.child_name)
      .single();

    if (!child) {
      issues.push({
        table: 'children',
        type: 'missing_data',
        child_name: oldRow.child_name
      });
      continue;
    }

    const { data: week } = await supabase
      .from('weeks')
      .select('*')
      .eq('child_id', child.id)
      .eq('week_start_date', oldRow.week_start_date)
      .single();

    if (!week) {
      issues.push({
        table: 'weeks',
        type: 'missing_data',
        child_name: oldRow.child_name,
        week_start_date: oldRow.week_start_date
      });
    } else if (week.theme !== oldRow.theme) {
      issues.push({
        table: 'weeks',
        type: 'data_mismatch',
        child_name: oldRow.child_name,
        week_start_date: oldRow.week_start_date,
        field: 'theme',
        old: oldRow.theme,
        new: week.theme
      });
    }
  }

  // ê²°ê³¼ ì¶œë ¥
  if (issues.length === 0) {
    console.log('âœ… ë“œë¦¬í”„íŠ¸ ì—†ìŒ - êµ¬/ì‹  ìŠ¤í‚¤ë§ˆ ì¼ì¹˜');
  } else {
    console.log(`âŒ ${issues.length}ê°œì˜ ë“œë¦¬í”„íŠ¸ ë°œê²¬:`);
    console.table(issues);
  }

  return issues;
}

// ë©”ì¸ ì‹¤í–‰
detectDrift().catch(console.error);
```

**ì‹¤í–‰**:
```bash
node scripts/drift-detection.js
```

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] ë“œë¦¬í”„íŠ¸ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± ì™„ë£Œ
- [ ] ì‹¤í–‰ ì‹œ ë“œë¦¬í”„íŠ¸ ì—†ìŒ í™•ì¸

---

#### âœ… Task 4.2: ë“œë¦¬í”„íŠ¸ ê²€ì¦ CI/CD í†µí•©
**íŒŒì¼**: `.github/workflows/drift-detection.yml`

```yaml
name: Drift Detection

on:
  schedule:
    - cron: '0 */6 * * *'  # 6ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰
  workflow_dispatch:  # ìˆ˜ë™ ì‹¤í–‰ ê°€ëŠ¥

jobs:
  detect-drift:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Install dependencies
        run: npm install

      - name: Run drift detection
        env:
          VITE_SUPABASE_URL: ${{ secrets.VITE_SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: node scripts/drift-detection.js

      - name: Notify on failure
        if: failure()
        uses: actions/github-script@v6
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'ğŸš¨ Drift Detection Failed',
              body: 'ë“œë¦¬í”„íŠ¸ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.',
              labels: ['bug', 'high-priority']
            })
```

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] GitHub Actions ì›Œí¬í”Œë¡œìš° ì¶”ê°€ë¨
- [ ] ìˆ˜ë™ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ
- [ ] 6ì‹œê°„ë§ˆë‹¤ ìë™ ì‹¤í–‰ í™•ì¸

---

### Day 8-9: ì´ì¤‘ì“°ê¸° ì¤€ë¹„

**ëª©í‘œ**: Phase 1ì—ì„œ ì‚¬ìš©í•  ì´ì¤‘ì“°ê¸° ë¡œì§ ì¤€ë¹„

#### âœ… Task 5.1: Edge Function ìŠ¤ì¼ˆë ˆí†¤ ì‘ì„±
**íŒŒì¼**: `supabase/functions/dual-write-habit/index.ts`

```typescript
import { serve } from 'https://deno.land/std@0.168.0/http/server.ts';
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders });
  }

  try {
    const supabase = createClient(
      Deno.env.get('SUPABASE_URL') ?? '',
      Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''
    );

    const { operation, data } = await req.json();

    switch (operation) {
      case 'create_week':
        return await createWeekDualWrite(supabase, data);
      case 'update_habit':
        return await updateHabitDualWrite(supabase, data);
      case 'toggle_completion':
        return await toggleCompletionDualWrite(supabase, data);
      default:
        throw new Error(`Unknown operation: ${operation}`);
    }
  } catch (error) {
    return new Response(
      JSON.stringify({ error: error.message }),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' }, status: 400 }
    );
  }
});

async function createWeekDualWrite(supabase: any, data: any) {
  // TODO: Phase 1ì—ì„œ êµ¬í˜„
  return new Response(
    JSON.stringify({ message: 'Not implemented yet' }),
    { headers: { ...corsHeaders, 'Content-Type': 'application/json' }, status: 501 }
  );
}

async function updateHabitDualWrite(supabase: any, data: any) {
  // TODO: Phase 1ì—ì„œ êµ¬í˜„
  return new Response(
    JSON.stringify({ message: 'Not implemented yet' }),
    { headers: { ...corsHeaders, 'Content-Type': 'application/json' }, status: 501 }
  );
}

async function toggleCompletionDualWrite(supabase: any, data: any) {
  // TODO: Phase 1ì—ì„œ êµ¬í˜„
  return new Response(
    JSON.stringify({ message: 'Not implemented yet' }),
    { headers: { ...corsHeaders, 'Content-Type': 'application/json' }, status: 501 }
  );
}
```

**ë°°í¬**:
```bash
npx supabase functions deploy dual-write-habit
```

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] Edge Function ìŠ¤ì¼ˆë ˆí†¤ ì‘ì„± ì™„ë£Œ
- [ ] Supabaseì— ë°°í¬ ì™„ë£Œ
- [ ] í˜¸ì¶œ ì‹œ 501 ì‘ë‹µ í™•ì¸ (ì•„ì§ ë¯¸êµ¬í˜„)

---

#### âœ… Task 5.2: Database Trigger ìŠ¤ì¼ˆë ˆí†¤ ì‘ì„±
**íŒŒì¼**: `supabase/migrations/004_create_dual_write_triggers.sql`

```sql
-- ì´ì¤‘ì“°ê¸° íŠ¸ë¦¬ê±° í•¨ìˆ˜ (Edge Function ì‹¤íŒ¨ ì‹œ ë°±ì—…ìš©)
CREATE OR REPLACE FUNCTION sync_old_to_new()
RETURNS TRIGGER AS $$
BEGIN
  -- TODO: Phase 1ì—ì„œ êµ¬í˜„
  -- ì§€ê¸ˆì€ ë¡œê·¸ë§Œ ë‚¨ê¹€
  RAISE NOTICE 'Trigger fired for table %, operation %', TG_TABLE_NAME, TG_OP;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- íŠ¸ë¦¬ê±° ìƒì„± (ì•„ì§ í™œì„±í™”í•˜ì§€ ì•ŠìŒ)
CREATE TRIGGER trigger_habit_tracker_dual_write
  AFTER INSERT OR UPDATE OR DELETE ON habit_tracker
  FOR EACH ROW
  EXECUTE FUNCTION sync_old_to_new();

-- âš ï¸ ì¤‘ìš”: íŠ¸ë¦¬ê±°ëŠ” ìƒì„±ë˜ì§€ë§Œ í•¨ìˆ˜ê°€ ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•ŠìŒ
-- Phase 1ì—ì„œ ì‹¤ì œ ë¡œì§ êµ¬í˜„
```

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] íŠ¸ë¦¬ê±° í•¨ìˆ˜ ìŠ¤ì¼ˆë ˆí†¤ ì‘ì„± ì™„ë£Œ
- [ ] íŠ¸ë¦¬ê±° ìƒì„± ì™„ë£Œ (ì•„ì§ ë™ì‘í•˜ì§€ ì•ŠìŒ)

---

### Day 10: Phase 0 ìµœì¢… ê²€ì¦ ë° ìŠ¹ì¸

#### âœ… Task 6.1: Phase 0 ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

**ì¸í”„ë¼**:
- [ ] 7ê°œ í…Œì´ë¸” ìƒì„± ì™„ë£Œ
- [ ] ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ (CONCURRENTLY)
- [ ] RLS ì •ì±… ìƒì„± ì™„ë£Œ (ë¹„í™œì„±í™” ìƒíƒœ)
- [ ] ì™¸ë˜ í‚¤ ì œì•½ ì¡°ê±´ ì¡´ì¬ (`NOT VALID`)

**ë°ì´í„°**:
- [ ] ë°±í•„ ì™„ë£Œ (ëª¨ë“  ë°ì´í„° ì´ê´€)
- [ ] ë°ì´í„° ê°œìˆ˜ ì¼ì¹˜ í™•ì¸
- [ ] ìƒ˜í”Œ ë°ì´í„° ë‚´ìš© ì¼ì¹˜ í™•ì¸

**ìë™í™”**:
- [ ] ë°±í•„ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± ì™„ë£Œ
- [ ] ë“œë¦¬í”„íŠ¸ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± ì™„ë£Œ
- [ ] CI/CD í†µí•© ì™„ë£Œ (6ì‹œê°„ë§ˆë‹¤ ìë™ ì‹¤í–‰)

**ì´ì¤‘ì“°ê¸° ì¤€ë¹„**:
- [ ] Edge Function ìŠ¤ì¼ˆë ˆí†¤ ë°°í¬ ì™„ë£Œ
- [ ] Database Trigger ìŠ¤ì¼ˆë ˆí†¤ ìƒì„± ì™„ë£Œ

**ë¬¸ì„œí™”**:
- [ ] Week 1 íšŒê³  ì‘ì„± ì™„ë£Œ
- [ ] Phase 0 íšŒê³  ì‘ì„± ì™„ë£Œ

---

#### âœ… Task 6.2: Phase 0 íšŒê³  ë¬¸ì„œ ì‘ì„±
**íŒŒì¼**: `docs/phase0-retrospective.md`

```markdown
# Phase 0 íšŒê³ : ì¤€ë¹„ ë‹¨ê³„ ì™„ë£Œ

## ëª©í‘œ ë‹¬ì„±ë„
- âœ… ì„€ë„ ìŠ¤í‚¤ë§ˆ êµ¬ì¶• ì™„ë£Œ
- âœ… ë°ì´í„° ë°±í•„ ì™„ë£Œ
- âœ… ê²€ì¦ ìë™í™” êµ¬ì¶• ì™„ë£Œ
- âœ… ì´ì¤‘ì“°ê¸° ì¤€ë¹„ ì™„ë£Œ

## ì£¼ìš” ì„±ê³¼
1. **ë¬´ì¤‘ë‹¨ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤€ë¹„ ì™„ë£Œ**: í”„ë¡œë•ì…˜ì— ì˜í–¥ ì—†ì´ ìƒˆ ìŠ¤í‚¤ë§ˆ êµ¬ì¶•
2. **ë°ì´í„° ë¬´ê²°ì„± ë³´ì¥**: ë°±í•„ + ë“œë¦¬í”„íŠ¸ ê²€ì¦ìœ¼ë¡œ 100% ì¼ì¹˜ í™•ì¸
3. **ìë™í™” êµ¬ì¶•**: CI/CDë¡œ 6ì‹œê°„ë§ˆë‹¤ ìë™ ê²€ì¦

## ë°ì´í„° í†µê³„
- ì´ ì•„ì´: XXëª…
- ì´ ì£¼ì°¨: XXê°œ
- ì´ ìŠµê´€: XXê°œ
- ì´ ì™„ë£Œ ê¸°ë¡: XXê°œ
- ë°±í•„ ì†Œìš” ì‹œê°„: XXë¶„
- ë“œë¦¬í”„íŠ¸ ê²€ì¦ ì†Œìš” ì‹œê°„: XXì´ˆ

## ì´ìŠˆ ë° í•´ê²°
### Issue 1: (ì´ìŠˆê°€ ìˆì—ˆë‹¤ë©´ ê¸°ë¡)
**ë¬¸ì œ**: ...
**í•´ê²°**: ...

## ë‹¤ìŒ ë‹¨ê³„ (Phase 1)
- ì´ì¤‘ì“°ê¸° ë¡œì§ êµ¬í˜„
- í…œí”Œë¦¿ ê¸°ëŠ¥ ê°œë°œ
- Feature Flag ì„¤ì •

## ìŠ¹ì¸
- [ ] ê¸°ìˆ  ë¦¬ë“œ ìŠ¹ì¸
- [ ] PM ìŠ¹ì¸
- [ ] Phase 1 ì‹œì‘ ê°€ëŠ¥
```

**ì™„ë£Œ ê¸°ì¤€**:
- [ ] Phase 0 íšŒê³  ì‘ì„± ì™„ë£Œ
- [ ] íŒ€ ë¦¬ë·° ë° ìŠ¹ì¸ ì™„ë£Œ
- [ ] Phase 1 ì‹œì‘ ì¤€ë¹„ ì™„ë£Œ

---

## ğŸ¯ Phase 0 ì™„ë£Œ í›„ ë‹¤ìŒ ë‹¨ê³„

### Phase 1 Preview (4ì£¼)
1. **Week 1-2**: ì´ì¤‘ì“°ê¸° ë¡œì§ êµ¬í˜„ (Edge Function + Trigger)
2. **Week 3**: í…œí”Œë¦¿ ê¸°ëŠ¥ ê°œë°œ (ì‹  ìŠ¤í‚¤ë§ˆë§Œ ì‚¬ìš©)
3. **Week 4**: Feature Flag ì„¤ì • ë° ë‚´ë¶€ í…ŒìŠ¤íŠ¸ (5% íŠ¸ë˜í”½)

### ì„±ê³µ ê¸°ì¤€
- âœ… ì„€ë„ ìŠ¤í‚¤ë§ˆê°€ í”„ë¡œë•ì…˜ì— ì¡´ì¬
- âœ… ë°±í•„ë¡œ ë°ì´í„° 100% ì´ê´€ ì™„ë£Œ
- âœ… ë“œë¦¬í”„íŠ¸ ê²€ì¦ ìë™í™” ì‹¤í–‰ ì¤‘
- âœ… ì´ì¤‘ì“°ê¸° ì¤€ë¹„ ì™„ë£Œ (ìŠ¤ì¼ˆë ˆí†¤)
- âœ… í”„ë¡œë•ì…˜ ë‹¤ìš´íƒ€ì„ **0ë¶„**

---

## ğŸ“ ë¬¸ì œ ë°œìƒ ì‹œ

### ë°±í•„ ì‹¤íŒ¨
```bash
# ë¡¤ë°±
node scripts/rollback-backfill.js

# ë¡œê·¸ í™•ì¸
npx supabase logs --type=postgres
```

### ë“œë¦¬í”„íŠ¸ ë°œê²¬
```bash
# ìˆ˜ë™ ì¬ë°±í•„
node scripts/backfill.js --force

# íŠ¹ì • í…Œì´ë¸”ë§Œ
node scripts/backfill.js --table=children
```

### ê¸´ê¸‰ ì—°ë½ì²˜
- ê¸°ìˆ  ë¦¬ë“œ: @tech-lead
- PM: @product-manager
- Supabase Support: support@supabase.com

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-10-11
**ì‘ì„±ì**: Claude Code (Phase 0 ìë™ ìƒì„±)
